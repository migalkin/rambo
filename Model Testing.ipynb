{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# MyTorch imports\n",
    "from mytorch.utils.goodies import *\n",
    "\n",
    "# Local imports\n",
    "from parse_wd15k import Quint\n",
    "from load import DataManager\n",
    "from utils import *\n",
    "from evaluation import EvaluationBench, acc, mrr, mr, hits_at, evaluate_pointwise\n",
    "from corruption import Corruption\n",
    "from sampler import SimpleSampler, NeighbourhoodSampler\n",
    "from loops import training_loop\n",
    "\n",
    "# Model related imports\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "# Local imports\n",
    "from utils import *\n",
    "\n",
    "\"\"\"\n",
    "    CONFIG Things\n",
    "\"\"\"\n",
    "\n",
    "# Clamp the randomness\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\"\"\"\n",
    "    Explanation:\n",
    "        *ENT_POS_FILTERED* \n",
    "            a flag which if False, implies that while making negatives, \n",
    "                we should exclude entities that appear ONLY in non-corrupting positions.\n",
    "            Do not turn it off if the experiment is about predicting qualifiers, of course.\n",
    "\n",
    "        *POSITIONS*\n",
    "            the positions on which we should inflect the negatives.\n",
    "\"\"\"\n",
    "DEFAULT_CONFIG = {\n",
    "    'EMBEDDING_DIM': 50,\n",
    "    'NORM_FOR_NORMALIZATION_OF_ENTITIES': 2,\n",
    "    'NORM_FOR_NORMALIZATION_OF_RELATIONS': 2,\n",
    "    'SCORING_FUNCTION_NORM': 1,\n",
    "    'MARGIN_LOSS': 1,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NEGATIVE_SAMPLING_PROBS': [0.3, 0.0, 0.2, 0.5],\n",
    "    'NEGATIVE_SAMPLING_TIMES': 10,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 1000,\n",
    "    'STATEMENT_LEN': -1,\n",
    "    'EVAL_EVERY': 10,\n",
    "    'WANDB': False,\n",
    "    'RUN_TESTBENCH_ON_TRAIN': True,\n",
    "    'DATASET': 'fb15k237',\n",
    "    'CORRUPTION_POSITIONS': [0, 2],\n",
    "    'DEVICE': 'cpu',\n",
    "    'ENT_POS_FILTERED': True,\n",
    "    'USE_TEST': False,\n",
    "    'MAX_QPAIRS': 43,\n",
    "    'NUM_FILTER': 5,\n",
    "    'NEIGHBOUR': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating hop1 hash.\n",
      "Creating hop2 hash. This will take around 2-3 mins.\n",
      "14541\n"
     ]
    }
   ],
   "source": [
    "# Custom Sanity Checks\n",
    "if DEFAULT_CONFIG['DATASET'] == 'wd15k':\n",
    "    assert DEFAULT_CONFIG['STATEMENT_LEN'] is not None, \\\n",
    "        \"You use WD15k dataset and don't specify whether to treat them as quints or not. Nicht cool'\"\n",
    "if max(DEFAULT_CONFIG['CORRUPTION_POSITIONS']) > 2:     # If we're corrupting something apart from S and O\n",
    "    assert DEFAULT_CONFIG['ENT_POS_FILTERED'] is False, \\\n",
    "        f\"Since we're corrupting objects at pos. {DEFAULT_CONFIG['CORRUPTION_POSITIONS']}, \" \\\n",
    "        f\"You must allow including entities which appear exclusively in qualifiers, too!\"\n",
    "\n",
    "\"\"\"\n",
    "    Load data based on the args/config\n",
    "\"\"\"\n",
    "data = DataManager.load(config=DEFAULT_CONFIG)()\n",
    "if DEFAULT_CONFIG['NEIGHBOUR']:\n",
    "    assert DEFAULT_CONFIG['DATASET'] == 'fb15k237'\n",
    "    hashes = create_neighbourhood_hashes(data)\n",
    "try:\n",
    "    training_triples, valid_triples, test_triples, num_entities, num_relations = data.values()\n",
    "except ValueError:\n",
    "    raise ValueError(f\"Honey I broke the loader for {DEFAULT_CONFIG['DATASET']}\")\n",
    "\n",
    "if DEFAULT_CONFIG['ENT_POS_FILTERED']:\n",
    "    ent_excluded_from_corr = DataManager.gather_missing_entities(data=training_triples + valid_triples + test_triples,\n",
    "                                                                 positions=DEFAULT_CONFIG['CORRUPTION_POSITIONS'],\n",
    "                                                                 n_ents=num_entities)\n",
    "    DEFAULT_CONFIG['NUM_ENTITIES_FILTERED'] = len(ent_excluded_from_corr)\n",
    "else:\n",
    "    ent_excluded_from_corr = []\n",
    "    DEFAULT_CONFIG['NUM_ENTITIES_FILTERED'] = len(ent_excluded_from_corr)\n",
    "\n",
    "print(num_entities-DEFAULT_CONFIG['NUM_ENTITIES_FILTERED'])\n",
    "DEFAULT_CONFIG['NUM_ENTITIES'] = num_entities\n",
    "DEFAULT_CONFIG['NUM_RELATIONS'] = num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['DEVICE'] = torch.device(config['DEVICE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR MODEL COMES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModule(nn.Module):\n",
    "    \"\"\"A base class for all of the models.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.margin_ranking_loss_size_average: bool = None\n",
    "        self.entity_embedding_max_norm: Optional[int] = None\n",
    "        self.entity_embedding_norm_type: int = 2\n",
    "        self.hyper_params = [config['EMBEDDING_DIM'],\n",
    "                             config['MARGIN_LOSS'],\n",
    "                             config['LEARNING_RATE']]\n",
    "\n",
    "        # Device selection\n",
    "        self.device: torch.device = config['DEVICE']\n",
    "\n",
    "        # Loss\n",
    "        self.margin_loss = config['MARGIN_LOSS']\n",
    "        self.criterion = nn.MarginRankingLoss(\n",
    "            margin=self.margin_loss,\n",
    "            reduction='mean' if self.margin_ranking_loss_size_average else 'sum'\n",
    "        )\n",
    "\n",
    "        # Entity dimensions\n",
    "        #: The number of entities in the knowledge graph\n",
    "        self.num_entities = config['NUM_ENTITIES']\n",
    "        #: The number of unique relation types in the knowledge graph\n",
    "        self.num_relations = config['NUM_RELATIONS']\n",
    "        #: The dimension of the embeddings to generate\n",
    "        self.embedding_dim = config['EMBEDDING_DIM']\n",
    "\n",
    "        self.entity_embeddings = nn.Embedding(\n",
    "            self.num_entities,\n",
    "            self.embedding_dim,\n",
    "            norm_type=self.entity_embedding_norm_type,\n",
    "            max_norm=self.entity_embedding_max_norm,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "    def __init_subclass__(cls, **kwargs):  # noqa: D105\n",
    "        if not getattr(cls, 'model_name', None):\n",
    "            raise TypeError('missing model_name class attribute')\n",
    "\n",
    "    def _get_entity_embeddings(self, entities: torch.Tensor) -> torch.Tensor:\n",
    "        return self.entity_embeddings(entities).view(-1, self.embedding_dim)\n",
    "\n",
    "    def _compute_loss(self, positive_scores: torch.Tensor, negative_scores: torch.Tensor) -> torch.Tensor:\n",
    "        y = np.repeat([-1], repeats=positive_scores.shape[0])\n",
    "        y = torch.tensor(y, dtype=torch.float, device=self.device)\n",
    "\n",
    "        loss = self.criterion(positive_scores, negative_scores, y)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def slice_triples(triples: torch.Tensor, slices: int):\n",
    "    \"\"\" Slice in 3 or 5 as needed \"\"\"\n",
    "    if slices == 5:\n",
    "        return triples[:, 0], triples[:, 1], triples[:, 2], triples[:, 3], triples[:, 4]\n",
    "    elif slices == 3:\n",
    "        return triples[:, 0], triples[:, 1], triples[:, 2]\n",
    "    else:\n",
    "        return triples[:, 0], triples[:, 2::2], triples[:, 1::2]  # subject, all other entities, all relations\n",
    "\n",
    "\n",
    "class ConvKB(BaseModule):\n",
    "    \"\"\"\n",
    "    An implementation of TransE [borders2013]_.\n",
    "     This model considers a relation as a translation from the head to the tail entity.\n",
    "    .. [borders2013] Bordes, A., *et al.* (2013). `Translating embeddings for modeling multi-relational data\n",
    "                     <http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf>`_\n",
    "                     . NIPS.\n",
    "    .. seealso::\n",
    "       - Alternative implementation in OpenKE: https://github.com/thunlp/OpenKE/blob/OpenKE-PyTorch/models/TransE.py\n",
    "\n",
    "\n",
    "        Modifications to use this to work with quints can be turned on/off with a flag.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = 'TransE MM'\n",
    "\n",
    "    def __init__(self, config) -> None:\n",
    "\n",
    "        self.margin_ranking_loss_size_average: bool = True\n",
    "        self.entity_embedding_max_norm: Optional[int] = None\n",
    "        self.entity_embedding_norm_type: int = 2\n",
    "        self.model_name = 'TransE MM'\n",
    "        super().__init__(config)\n",
    "        self.statement_len = config['STATEMENT_LEN']\n",
    "\n",
    "        # Embeddings\n",
    "        self.l_p_norm_entities = config['NORM_FOR_NORMALIZATION_OF_ENTITIES']\n",
    "        self.scoring_fct_norm = config['SCORING_FUNCTION_NORM']\n",
    "        self.relation_embeddings = nn.Embedding(config['NUM_RELATIONS'], config['EMBEDDING_DIM'], padding_idx=0)\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        \n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=1, \n",
    "                              out_channels=config['NUM_FILTER'], kernel_size= (config['MAX_QPAIRS'],1), \n",
    "                             bias=True)\n",
    "        \n",
    "        self.fc = nn.Linear(config['NUM_FILTER']*self.embedding_dim,1, bias=False)\n",
    "        \n",
    "        self._initialize()\n",
    "\n",
    "        # Make pad index zero. # TODO: Should pad index be configurable? Probably not, right? Cool? Cool.\n",
    "        # self.entity_embeddings.weight.data[0] = torch.zeros_like(self.entity_embeddings.weight[0], requires_grad=True)\n",
    "        # self.relation_embeddings.weight.data[0] = torch.zeros_like(self.relation_embeddings.weight[0], requires_grad=True)\n",
    "\n",
    "    def _initialize(self):\n",
    "        embeddings_init_bound = 6 / np.sqrt(self.config['EMBEDDING_DIM'])\n",
    "        nn.init.uniform_(\n",
    "            self.entity_embeddings.weight.data,\n",
    "            a=-embeddings_init_bound,\n",
    "            b=+embeddings_init_bound,\n",
    "        )\n",
    "        nn.init.uniform_(\n",
    "            self.relation_embeddings.weight.data,\n",
    "            a=-embeddings_init_bound,\n",
    "            b=+embeddings_init_bound,\n",
    "        )\n",
    "\n",
    "        norms = torch.norm(self.relation_embeddings.weight,\n",
    "                           p=self.config['NORM_FOR_NORMALIZATION_OF_RELATIONS'], dim=1).data\n",
    "        self.relation_embeddings.weight.data = self.relation_embeddings.weight.data.div(\n",
    "            norms.view(self.num_relations, 1).expand_as(self.relation_embeddings.weight))\n",
    "\n",
    "        self.relation_embeddings.weight.data[0] = torch.zeros(1, self.embedding_dim)\n",
    "        self.entity_embeddings.weight.data[0] = torch.zeros(1, self.embedding_dim)  # zeroing the padding index\n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self, triples):\n",
    "        scores = self._score_triples(triples)\n",
    "        return scores\n",
    "\n",
    "    def forward(self, batch_positives, batch_negatives) \\\n",
    "            -> Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "\n",
    "        # Normalize embeddings of entities\n",
    "        norms = torch.norm(self.entity_embeddings.weight, p=self.l_p_norm_entities, dim=1).data\n",
    "        \n",
    "        self.entity_embeddings.weight.data = self.entity_embeddings.weight.data.div(\n",
    "            norms.view(self.num_entities, 1).expand_as(self.entity_embeddings.weight))\n",
    "        \n",
    "        self.entity_embeddings.weight.data[0] = torch.zeros(1, self.embedding_dim)  # zeroing the padding index\n",
    "\n",
    "        positive_scores = self._score_triples(batch_positives)\n",
    "        negative_scores = self._score_triples(batch_negatives)\n",
    "        loss = self._compute_loss(positive_scores=positive_scores, negative_scores=negative_scores)\n",
    "        return (positive_scores, negative_scores), loss\n",
    "\n",
    "    def _score_triples(self, triples) -> torch.Tensor:\n",
    "        \"\"\" Get triple/quint embeddings, and compute scores \"\"\"\n",
    "        scores = self._compute_scores(*self._get_triple_embeddings(triples))\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def _compute_scores(self, head_embeddings, relation_embeddings, tail_embeddings,\n",
    "                        qual_relation_embeddings=None, qual_entity_embeddings=None):\n",
    "        \"\"\"\n",
    "            Compute the scores based on the head, relation, and tail embeddings.\n",
    "\n",
    "        :param head_embeddings: embeddings of head entities of dimension batchsize x embedding_dim\n",
    "        :param relation_embeddings: embeddings of relation embeddings of dimension batchsize x embedding_dim\n",
    "        :param tail_embeddings: embeddings of tail entities of dimension batchsize x embedding_dim\n",
    "        :param qual_entity_embeddings: embeddings of qualifier relations of dimensinos batchsize x embeddig_dim\n",
    "        :param qual_relation_embeddings: embeddings of qualifier entities of dimension batchsize x embedding_dim\n",
    "        :return: Tensor of dimension batch_size containing the scores for each batch element\n",
    "        \"\"\"\n",
    "        \n",
    "        statement_emb = torch.zeros(head_embeddings.shape[0],\n",
    "                                    relation_embeddings.shape[1]*2+1,\n",
    "                                     head_embeddings.shape[1], \n",
    "                                 device=self.config['DEVICE'],\n",
    "                                   dtype=head_embeddings.dtype) # 1 for head embedding\n",
    "        \n",
    "        # Assignment\n",
    "        statement_emb[:,0] = head_embeddings\n",
    "        statement_emb[:,1::2] = relation_embeddings\n",
    "        statement_emb[:,2::2] = tail_embeddings\n",
    "        \n",
    "        \n",
    "        # Convolutional operation\n",
    "        statement_emb = F.relu(self.conv(statement_emb.unsqueeze(1))).squeeze() # bs*number_of_filter*emb_dim   \n",
    "        \n",
    "        statement_emb = statement_emb.view(statement_emb.shape[0], -1)\n",
    "        score = self.fc(statement_emb)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def _get_triple_embeddings(self, triples):\n",
    "        \n",
    "        head, statement_entities, statement_relations = slice_triples(triples, -1)\n",
    "        return (\n",
    "            self._get_entity_embeddings(head),\n",
    "            self.relation_embeddings(statement_relations),\n",
    "            self.entity_embeddings(statement_entities)\n",
    "        )\n",
    "\n",
    "    def _get_relation_embeddings(self, relations):\n",
    "        return self.relation_embeddings(relations).view(-1, self.embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvKB(config)\n",
    "model.to(config['DEVICE'])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'index': np.array(training_triples + test_triples), 'eval': np.array(valid_triples)}\n",
    "_data = {'index': np.array(valid_triples + test_triples), 'eval': np.array(training_triples)}\n",
    "tr_data = {'train': np.array(training_triples), 'valid': data['eval']}\n",
    "\n",
    "eval_metrics = [acc, mrr, mr, partial(hits_at, k=3), partial(hits_at, k=5), partial(hits_at, k=10)]\n",
    "evaluation_valid = EvaluationBench(data, model, bs=8000,\n",
    "                                   metrics=eval_metrics, filtered=True,\n",
    "                                   n_ents=num_entities,\n",
    "                                   excluding_entities=ent_excluded_from_corr,\n",
    "                                   positions=config.get('CORRUPTION_POSITIONS', None))\n",
    "evaluation_train = EvaluationBench(_data, model, bs=8000,\n",
    "                                   metrics=eval_metrics, filtered=True,\n",
    "                                   n_ents=num_entities,\n",
    "                                   excluding_entities=ent_excluded_from_corr,\n",
    "                                   positions=config.get('CORRUPTION_POSITIONS', None), trim=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"epochs\": config['EPOCHS'],\n",
    "        \"data\": tr_data,\n",
    "        \"opt\": optimizer,\n",
    "        \"train_fn\": model,\n",
    "        \"neg_generator\": Corruption(n=num_entities, excluding=ent_excluded_from_corr,\n",
    "                                    position=list(range(0, config['MAX_QPAIRS'], 2))),\n",
    "        \"device\": config['DEVICE'],\n",
    "        \"data_fn\": partial(SimpleSampler, bs=config[\"BATCH_SIZE\"]),\n",
    "        \"eval_fn_trn\": evaluate_pointwise,\n",
    "        \"val_testbench\": evaluation_valid.run,\n",
    "        \"trn_testbench\": evaluation_train.run,\n",
    "        \"eval_every\": config['EVAL_EVERY'],\n",
    "        \"log_wandb\": config['WANDB'],\n",
    "        \"run_trn_testbench\": config['RUN_TESTBENCH_ON_TRAIN']\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "traces = training_loop(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_simple = SimpleSampler(tr_data['train'], config[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_neighbour = NeighbourhoodSampler(tr_data['train'], config[\"BATCH_SIZE\"], hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in sampler_neighbour:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 3), 20, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].shape, len(d[1][0]), len(d[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
